{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99b23ab-e5f8-4d8b-a162-b68f8ecf85f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2a53a9-d131-4fb2-9061-0e875326b214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.7.1+cu126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00, 12.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SD pipeline & tokenizer ready\n",
      " LoRA attached with: {'to_q', 'to_v', 'to_out.0', 'to_k'}\n",
      "\n",
      " Training LoRA for style: oil_painting\n",
      " Epoch 1/10\n",
      " Epoch 2/10\n",
      " Epoch 3/10\n",
      " Epoch 4/10\n",
      " Epoch 5/10\n",
      " Epoch 6/10\n",
      " Epoch 7/10\n",
      " Epoch 8/10\n",
      " Epoch 9/10\n",
      " Epoch 10/10\n",
      " Saved LoRA for oil_painting: lora_oil_painting.pt\n",
      " Finished oil_painting!\n",
      "\n",
      " Training LoRA for style: mosaic\n",
      " Epoch 1/10\n",
      " Epoch 2/10\n",
      " Epoch 3/10\n",
      " Epoch 4/10\n",
      " Epoch 5/10\n",
      " Epoch 6/10\n",
      " Epoch 7/10\n",
      " Epoch 8/10\n",
      " Epoch 9/10\n",
      " Epoch 10/10\n",
      " Saved LoRA for mosaic: lora_mosaic.pt\n",
      " Finished mosaic!\n",
      "\n",
      " Training LoRA for style: crayon\n",
      " Epoch 1/10\n",
      " Epoch 2/10\n",
      " Epoch 3/10\n",
      " Epoch 4/10\n",
      " Epoch 5/10\n",
      " Epoch 6/10\n",
      " Epoch 7/10\n",
      " Epoch 8/10\n",
      " Epoch 9/10\n",
      " Epoch 10/10\n",
      " Saved LoRA for crayon: lora_crayon.pt\n",
      " Finished crayon!\n",
      "\n",
      " Training LoRA for style: pencil_sketch\n",
      " Epoch 1/10\n",
      " Epoch 2/10\n",
      " Epoch 3/10\n",
      " Epoch 4/10\n",
      " Epoch 5/10\n",
      " Epoch 6/10\n",
      " Epoch 7/10\n",
      " Epoch 8/10\n",
      " Epoch 9/10\n",
      " Epoch 10/10\n",
      " Saved LoRA for pencil_sketch: lora_pencil_sketch.pt\n",
      " Finished pencil_sketch!\n",
      "\n",
      " Training LoRA for style: watercolor\n",
      " Epoch 1/10\n",
      " Epoch 2/10\n",
      " Epoch 3/10\n",
      " Epoch 4/10\n",
      " Epoch 5/10\n",
      " Epoch 6/10\n",
      " Epoch 7/10\n",
      " Epoch 8/10\n",
      " Epoch 9/10\n",
      " Epoch 10/10\n",
      " Saved LoRA for watercolor: lora_watercolor.pt\n",
      " Finished watercolor!\n",
      "\n",
      " All styles processed! Ready for style transfer tests.\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "#  1. Imports\n",
    "# ================================================================\n",
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from datasets import load_dataset\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "# ================================================================\n",
    "#  2. Device\n",
    "# ================================================================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "\n",
    "# ================================================================\n",
    "#  3. Load Stable Diffusion pipeline\n",
    "# ================================================================\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-v1-5\",\n",
    "    torch_dtype=torch.float16\n",
    ").to(device)\n",
    "\n",
    "tokenizer = pipe.tokenizer\n",
    "print(\" SD pipeline & tokenizer ready\")\n",
    "\n",
    "# ================================================================\n",
    "#  4. LoRA config for UNet transformer blocks\n",
    "# ================================================================\n",
    "lora_config = LoraConfig(\n",
    "    r=4,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"to_q\", \"to_k\", \"to_v\", \"to_out.0\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\"\n",
    ")\n",
    "\n",
    "pipe.unet = get_peft_model(pipe.unet, lora_config)\n",
    "print(\" LoRA attached with:\", lora_config.target_modules)\n",
    "\n",
    "# ================================================================\n",
    "#  5. Define transform for your dataset\n",
    "# ================================================================\n",
    "torch_transform = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "def transform(batch):\n",
    "    batch[\"image\"] = [\n",
    "        torch_transform(img.convert(\"RGB\")) for img in batch[\"image\"]\n",
    "    ]\n",
    "    return batch\n",
    "\n",
    "# ================================================================\n",
    "#  6. Loop through each style folder\n",
    "# ================================================================\n",
    "styles = [\"oil_painting\", \"mosaic\", \"crayon\", \"pencil_sketch\", \"watercolor\"]\n",
    "\n",
    "epochs = 20 \n",
    "batch_size = 4 \n",
    "\n",
    "for style in styles:\n",
    "    print(f\"\\n Training LoRA for style: {style}\")\n",
    "\n",
    "    dataset = load_dataset(\n",
    "        \"imagefolder\",\n",
    "        data_dir=f\"style_dataset/{style}\"\n",
    "    )[\"train\"]\n",
    "\n",
    "    dataset = dataset.with_transform(transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    optimizer = torch.optim.Adam(pipe.unet.parameters(), lr=1e-4)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\" Epoch {epoch + 1}/{epochs}\")\n",
    "        for step, batch in enumerate(dataloader):\n",
    "            images = batch[\"image\"].to(device)\n",
    "            captions = [f\"A {style} artwork\"] * images.size(0)\n",
    "\n",
    "            encoding = tokenizer(\n",
    "                captions,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                max_length=tokenizer.model_max_length,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "\n",
    "            input_ids = encoding.input_ids.to(device)\n",
    "\n",
    "    save_name = f\"lora_{style}.pt\"\n",
    "    torch.save(pipe.unet.state_dict(), save_name)\n",
    "    print(f\" Saved LoRA for {style}: {save_name}\")\n",
    "\n",
    "    test_image = Image.open(\"test.jpg\").convert(\"RGB\").resize((512, 512))\n",
    "    print(f\" Finished {style}!\")\n",
    "\n",
    "print(\"\\n All styles processed! Ready for style transfer tests.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926b84e0-2d4a-427c-bae9-a068014d19ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SD LoRA Env",
   "language": "python",
   "name": "sd-lora-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
